{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35d17fd",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f202fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487bc686",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = pd.read_csv(\"/nfs/turbo/hrg/data_detection/outputs_pipeline/4_pubs_sents_preds_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5ea705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 402637 entries, 0 to 402636\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   paper_id            402637 non-null  int64 \n",
      " 1   paper_title         364875 non-null  object\n",
      " 2   paper_section       379748 non-null  object\n",
      " 3   sentence_text       402637 non-null  object\n",
      " 4   dataset_prediction  7486 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "citations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433fba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_true = citations[~citations.dataset_prediction.isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5611b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7486 entries, 0 to 7485\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   paper_id            7486 non-null   int64 \n",
      " 1   paper_title         6754 non-null   object\n",
      " 2   paper_section       6948 non-null   object\n",
      " 3   sentence_text       7486 non-null   object\n",
      " 4   dataset_prediction  7486 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 292.5+ KB\n"
     ]
    }
   ],
   "source": [
    "citations_true.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7b73e",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741981cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openie import StanfordOpenIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ee1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://github.com/philipperemy/stanford-openie-python\n",
    "def extract_triple(text):\n",
    "    with StanfordOpenIE() as client:\n",
    "        return client.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8502cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADR data are collected from the major depositary bank websites: Bank of New York, Citibank, the Deutsche Bank, and JPMorgan. \n",
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-78ba13d7deab48de.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'ADR data', 'relation': 'are', 'object': 'collected'},\n",
       " {'subject': 'ADR data',\n",
       "  'relation': 'are collected from',\n",
       "  'object': 'major bank websites'},\n",
       " {'subject': 'ADR data',\n",
       "  'relation': 'are collected from',\n",
       "  'object': 'major depositary bank websites'},\n",
       " {'subject': 'New York', 'relation': 'of Bank is', 'object': 'Deutsche Bank'},\n",
       " {'subject': 'ADR data',\n",
       "  'relation': 'are collected from',\n",
       "  'object': 'bank websites'},\n",
       " {'subject': 'ADR data',\n",
       "  'relation': 'are collected from',\n",
       "  'object': 'depositary bank websites'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "print(citations_true.sentence_text[0])\n",
    "extract_triple(citations_true.sentence_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0187897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the non-ADR cross-listed shares (direct listing and New York Registered shares), we obtain the name of the firms, type of listing from the NYSE, Nasdaq, and AMEX websites. \n",
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-68493c7d9c0549c2.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'we',\n",
       "  'relation': 'obtain name For',\n",
       "  'object': 'non-ADR cross-listed shares'},\n",
       " {'subject': 'firms', 'relation': 'type from', 'object': 'NYSE websites'},\n",
       " {'subject': 'we', 'relation': 'obtain', 'object': 'name'},\n",
       " {'subject': 'we', 'relation': 'obtain name For', 'object': 'non-ADR shares'},\n",
       " {'subject': 'we',\n",
       "  'relation': 'obtain name For',\n",
       "  'object': 'cross-listed shares'},\n",
       " {'subject': 'firms', 'relation': 'type of', 'object': 'listing'},\n",
       " {'subject': 'we', 'relation': 'obtain name For', 'object': 'shares'},\n",
       " {'subject': 'we', 'relation': 'obtain', 'object': 'name of firms'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(citations_true.sentence_text[1])\n",
    "eg1 = extract_triple(citations_true.sentence_text[1])\n",
    "eg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c384ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In addition to linking our results to existing empirical studies, we provide some new evidence on our central implications by studying the autonomy of workers in a sample of firms in the National Organizations Survey, 1996-97 and . \n",
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-918c3f1425864090.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'autonomy', 'relation': 'is in', 'object': 'sample of firms'},\n",
       " {'subject': 'firms',\n",
       "  'relation': 'is in',\n",
       "  'object': 'National Organizations Survey'},\n",
       " {'subject': 'we', 'relation': 'linking', 'object': 'our results'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(citations_true.sentence_text[4])\n",
    "eg2 = extract_triple(citations_true.sentence_text[4])\n",
    "eg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45206bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data are drawn from the National Organizations Survey, 1996 -97 and 2002 (Kalleberg et al., 2001 Smith et al., 2005) . \n",
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-ded3fe6cfb3a4918.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'data',\n",
       "  'relation': 'are drawn from',\n",
       "  'object': 'National Organizations Survey'},\n",
       " {'subject': 'data', 'relation': 'are', 'object': 'drawn'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(citations_true.sentence_text[5])\n",
    "eg3 = extract_triple(citations_true.sentence_text[5])\n",
    "eg3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fbf90",
   "metadata": {},
   "source": [
    "Mask first VS mask later (but both went less ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b01f6328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-b3226e2b528e410b.props -preload openie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function StanfordOpenIE.__del__ at 0x2ba4f5322940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lizhouf/.local/lib/python3.8/site-packages/openie/openie.py\", line 90, in __del__\n",
      "    del os.environ['CORENLP_HOME']\n",
      "  File \"/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/os.py\", line 691, in __delitem__\n",
      "    raise KeyError(key) from None\n",
      "KeyError: 'CORENLP_HOME'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'number', 'relation': 'is taken', 'object': '8 urban areas'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': 'chengshi'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': 'counties'},\n",
       " {'subject': 'three geographic classifications',\n",
       "  'relation': 'based on Yearbook is',\n",
       "  'object': 'NBS 2003'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': '8 areas'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The number of enrolled students is taken from the China Statistical Yearbook (NBS 2003) , based on three geographic classifications: 8 urban areas (chengshi), counties and towns (xianzhen) and rural areas (nongcun).\"\n",
    "eg4 = extract_triple(text)\n",
    "eg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1438de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-bff17cbf88134a99.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'number', 'relation': 'is taken', 'object': '8 urban areas'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': 'chengshi'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': 'counties'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': '8 areas'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The number of enrolled students is taken from the DATASET , based on three geographic classifications: 8 urban areas (chengshi), counties and towns (xianzhen) and rural areas (nongcun).\"\n",
    "eg5 = extract_triple(text)\n",
    "eg5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "143cb4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-8b81ea37b34948a6.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'analysis', 'relation': 'takes', 'object': 'advantage'},\n",
       " {'subject': 'analysis', 'relation': 'takes', 'object': 'advantage of data'},\n",
       " {'subject': 'analysis',\n",
       "  'relation': 'takes',\n",
       "  'object': 'advantage of rich data'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The analysis takes advantage of rich data from the the Mexican Family Life Survey (MxFLS), which includes modules on health, anthropometry, cognitive skill, parental characteristics, and labor market outcomes. \"\n",
    "eg6 = extract_triple(text)\n",
    "eg6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2263c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server with command: java -Xmx8G -cp /home/lizhouf/stanfordnlp_resources/stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-6aad9a48dce947a9.props -preload openie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'analysis', 'relation': 'takes', 'object': 'advantage of data'},\n",
       " {'subject': 'analysis', 'relation': 'takes', 'object': 'advantage'},\n",
       " {'subject': 'analysis',\n",
       "  'relation': 'takes',\n",
       "  'object': 'advantage of rich data'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The analysis takes advantage of rich data from the the Mexican Family Life Survey (MxFLS)\"\n",
    "extract_triple(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd24931",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "991ace5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for similar jsons, keep the shortest json \n",
    "# include triples with and without the dataset_prediction (for possible coref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "908da909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: count the \"longest\" object\n",
    "def long_stuff(compare_stuff):  # a list of objects, return a list of longest objects\n",
    "    stf = pd.DataFrame()\n",
    "    stf[\"stuff\"] = compare_stuff\n",
    "    stf[\"len\"] = stf.stuff.apply(lambda x: x.count(\" \"))  # a list of object length\n",
    "    return stf.stuff[stf.len.idxmax()]  # we only interested in one object - the longest\n",
    "    # later, we can extract more info from the long object\n",
    "\n",
    "\n",
    "# Helper: get the stuff that are not a subject of others\n",
    "def no_subset(A):  # a list of strings\n",
    "    return list(set([x for x in A if not any(x in y and x != y for y in A)]))\n",
    "\n",
    "\n",
    "# Helper: Using rules to select tri:\n",
    "def select_triple(triplets):\n",
    "    \"\"\"\n",
    "    Extract a equence of subject-verb-object (SVO) triples\n",
    "    from a opie_tri fucntion acquired and processed doc,\n",
    "    including both active and passive entities and actions.\n",
    "\n",
    "    Args:\n",
    "        triplets are lists of dictionaries;\n",
    "        assume number of triplets >=2, i.e. len(triplets)>=2.\n",
    "\n",
    "    Yields:\n",
    "        List of dictionaries: the main/longest triplets from ``triplets``\n",
    "        representing a (subject, verb, object) triple.\n",
    "    \"\"\"\n",
    "    # initiate\n",
    "    selected = []\n",
    "    # only extract the longest subject\n",
    "    compare_sub = list(map(lambda x: x[\"subject\"], triplets))\n",
    "    subjects = no_subset(compare_sub)\n",
    "    for sub in subjects:\n",
    "        # extract different unique relations\n",
    "        tri_for_this_sub = [d for d in triplets if d[\"subject\"] == sub]\n",
    "        compare_rel = list(map(lambda x: x[\"relation\"], tri_for_this_sub))\n",
    "        relations = no_subset(compare_rel)\n",
    "        # for each of the relation, extract the longest obeject\n",
    "        for rel in relations:\n",
    "            tri_for_this_rel = [d for d in tri_for_this_sub if d[\"relation\"] == rel]\n",
    "            compare_obj = list(map(lambda x: x[\"object\"], tri_for_this_rel))\n",
    "            this_object = long_stuff(compare_obj)\n",
    "            selected.append({\"subject\": sub, \"relation\": rel, \"object\": this_object})\n",
    "\n",
    "    # for the selected ones, if both subject and object are the same\n",
    "    # we keep the one with the longest relation\n",
    "    if len(selected) > 1:\n",
    "        # initiate\n",
    "        re_select = []\n",
    "\n",
    "        # give group number\n",
    "        group_list = [0] * len(selected)\n",
    "        group_list[0] = 1  # initiate the first group\n",
    "        group_num = 1\n",
    "        pos = 0\n",
    "        # if both subject and object are the same\n",
    "        # assign the same group number\n",
    "        # but avoid reassignment\n",
    "        for i in range(len(selected)):\n",
    "            pos = i\n",
    "            for j in range(i + 1, len(selected)):\n",
    "                pos += 1\n",
    "                if group_list[pos] == 0:\n",
    "                    if selected[i][\"subject\"] == selected[j][\"subject\"] and \\\n",
    "                            selected[i][\"object\"] == selected[j][\"object\"]:\n",
    "                        group_list[pos] = group_num\n",
    "                    else:\n",
    "                        group_list[pos] = group_num + 1\n",
    "            group_num += 1\n",
    "\n",
    "        # for each group, find the longest relation\n",
    "        numbers = list(set(group_list))\n",
    "        selected_df = pd.DataFrame()\n",
    "        selected_df[\"tri\"] = selected\n",
    "        selected_df[\"grp\"] = group_list\n",
    "        for num in numbers:\n",
    "            # find all the triplets for this group\n",
    "            tri_for_this_grp = selected_df[selected_df.grp == num].tri\n",
    "            # acquire a list of relations in this group\n",
    "            compare_rel = list(map(lambda x: x[\"relation\"], tri_for_this_grp))\n",
    "            # find the longest relation\n",
    "            this_rel = long_stuff(compare_rel)\n",
    "            # get the subjects and objects for this group\n",
    "            # since these values are the same for each one of the values\n",
    "            # we extract the first one\n",
    "            this_subject = list(tri_for_this_grp)[0][\"subject\"]  # change a series to a list\n",
    "            this_object = list(tri_for_this_grp)[0][\"object\"]  # change a series to a list\n",
    "            # all the triplets in this group to the list\n",
    "            re_select.append({\"subject\": this_subject, \"relation\": this_rel, \"object\": this_object})\n",
    "\n",
    "        return re_select\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6f37c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'we', 'relation': 'obtain name For', 'object': 'non-ADR cross-listed shares'}, {'subject': 'firms', 'relation': 'type from', 'object': 'NYSE websites'}, {'subject': 'we', 'relation': 'obtain', 'object': 'name'}, {'subject': 'we', 'relation': 'obtain name For', 'object': 'non-ADR shares'}, {'subject': 'we', 'relation': 'obtain name For', 'object': 'cross-listed shares'}, {'subject': 'firms', 'relation': 'type of', 'object': 'listing'}, {'subject': 'we', 'relation': 'obtain name For', 'object': 'shares'}, {'subject': 'we', 'relation': 'obtain', 'object': 'name of firms'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'firms', 'relation': 'type from', 'object': 'NYSE websites'},\n",
       " {'subject': 'firms', 'relation': 'obtain name For', 'object': 'listing'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eg1)\n",
    "select_triple(eg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56a6a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'autonomy', 'relation': 'is in', 'object': 'sample of firms'}, {'subject': 'firms', 'relation': 'is in', 'object': 'National Organizations Survey'}, {'subject': 'we', 'relation': 'linking', 'object': 'our results'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'we', 'relation': 'linking', 'object': 'our results'},\n",
       " {'subject': 'autonomy', 'relation': 'is in', 'object': 'sample of firms'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eg2)\n",
    "select_triple(eg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbd3abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'data', 'relation': 'are drawn from', 'object': 'National Organizations Survey'}, {'subject': 'data', 'relation': 'are', 'object': 'drawn'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'data',\n",
       "  'relation': 'are drawn from',\n",
       "  'object': 'National Organizations Survey'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eg3)\n",
    "select_triple(eg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "029c4271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'number', 'relation': 'is taken', 'object': '8 urban areas'}, {'subject': 'number', 'relation': 'is taken', 'object': 'chengshi'}, {'subject': 'number', 'relation': 'is taken', 'object': 'counties'}, {'subject': 'three geographic classifications', 'relation': 'based on Yearbook is', 'object': 'NBS 2003'}, {'subject': 'number', 'relation': 'is taken', 'object': '8 areas'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'three geographic classifications',\n",
       "  'relation': 'based on Yearbook is',\n",
       "  'object': 'NBS 2003'},\n",
       " {'subject': 'number', 'relation': 'is taken', 'object': '8 urban areas'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eg4)\n",
    "select_triple(eg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2ba869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'number', 'relation': 'is taken', 'object': '8 urban areas'}, {'subject': 'number', 'relation': 'is taken', 'object': 'chengshi'}, {'subject': 'number', 'relation': 'is taken', 'object': 'counties'}, {'subject': 'number', 'relation': 'is taken', 'object': '8 areas'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'number', 'relation': 'is taken', 'object': '8 urban areas'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eg5)\n",
    "select_triple(eg5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b578e284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'analysis', 'relation': 'takes', 'object': 'advantage'}, {'subject': 'analysis', 'relation': 'takes', 'object': 'advantage of data'}, {'subject': 'analysis', 'relation': 'takes', 'object': 'advantage of rich data'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'subject': 'analysis',\n",
       "  'relation': 'takes',\n",
       "  'object': 'advantage of rich data'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eg6)\n",
    "select_triple(eg6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
